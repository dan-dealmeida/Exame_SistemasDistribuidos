RELATÓRIO DO PROJETO - QUEBRA DE SENHAS N CIFRAS

Este arquivo contém os links e as análises comparativas do projeto.

=======================================================
LINKS
=======================================================

- Link para o repositório no GitHub: https://github.com/dan-dealmeida/Exame_SistemasDistribuidos

=======================================================
ANÁLISE DE TEMPOS E ESCALABILIDADE
=======================================================

Para o teste de 6 dígitos numéricos (1.000.000 de combinações):
| Abordagem             | Tempo de Execução (6 dígitos numéricos) | 
|-----------------------|-----------------------------------------|
| Sequencial            | 0.0086s                                 | 
| Paralela (4 Threads)  | 0.1616s                                 |
| Distribuída (2 Clientes)| 0.0481s                               |       

Para o teste de 8 dígitos numéricos (100.000.000 de combinações):
| Abordagem             | Tempo de Execução (8 dígitos numéricos) |
|-----------------------|-----------------------------------------|
| Sequencial            | 1.0440s                                 |
| Paralela (4 Threads)  | 17.3309s                                | 
| Distribuída (2 Clientes)| 5.4292s                               | 

Para o teste de 9 dígitos numéricos (1.000.000.000 (1 bilhão) de combinações):
| Abordagem             | Tempo de Execução (9 dígitos numéricos) |
|-----------------------|-----------------------------------------|
| Sequencial            | 10.4465s                                 |
| Paralela (4 Threads)  | 184.9746s                                | 
| Distribuída (2 Clientes)| 56.5355s                               | 
Obs: O meu script usa o módulo threading do Python. O interpretador padrão do Python (CPython) possui algo chamado Global Interpreter Lock (GIL). Em termos simples, o GIL é um mecanismo que permite que apenas uma thread execute código Python por vez dentro de um único processo. Por isso ao aumentar o numero de threads eu noto que fica mais lento.

Para o teste de Senha Alfanumérica (minúsculas) de 6 Dígitos:Z
| Abordagem             | Tempo de Execução em segundos           |
|-----------------------|-----------------------------------------|
| Sequencial            | 4.6678                                  |
| Paralela (4 Threads)  | 139.6167                                | 
| Distribuída (2 Clientes)| 14.0052                               | 

Análise de Escalabilidade:
=======================================================
DESAFIOS ENCONTRADOS E MELHORIAS PROPOSTAS
=======================================================
Análise de Escalabilidade dos Resultados de Teste
Os resultados obtidos fornecem um panorama excelente e muito didático sobre a escalabilidade de diferentes arquiteturas de software para resolver um problema computacionalmente intensivo (CPU-Bound). A análise revela um vencedor claro em teoria, mas também expõe armadilhas cruciais na implementação prática em Python.

A observação de que o script utiliza o módulo threading é a chave para entender todo o comportamento.

1. Abordagem Sequencial (Linha de Base)
Esta abordagem serve como nosso ponto de referência (baseline).

Comportamento: A escalabilidade é perfeitamente linear. O tempo de execução aumenta em proporção direta ao número de combinações.

Evidência:

Ao aumentar a carga de trabalho em 100x (de 1M para 100M de combinações), o tempo aumentou ~120x (de 0.0086s para 1.0440s).

Ao aumentar a carga em 10x (de 100M para 1B de combinações), o tempo aumentou quase exatamente 10x (de 1.0440s para 10.4465s).

Conclusão: É um modelo previsível e eficiente em seu próprio núcleo, mas não "escala" no sentido de performance — para resolver um problema 10x maior, leva-se 10x mais tempo. É o desempenho que precisamos superar.

2. Abordagem Paralela (4 Threads)
Esta abordagem demonstra um caso clássico de escalabilidade negativa para tarefas CPU-Bound em Python.

Comportamento: O desempenho não apenas não melhora, como se degrada drasticamente à medida que a carga de trabalho aumenta. É consistentemente a pior de todas as abordagens.

Evidência:

No teste de 9 dígitos, a abordagem sequencial levou 10 segundos, enquanto a versão com 4 threads levou 185 segundos (mais de 18x mais lenta).

O mesmo padrão se repete em todos os testes, com a penalidade de desempenho piorando com o aumento da carga.

Causa Raiz (O porquê): O Global Interpreter Lock (GIL) do Python. O GIL é um mutex que protege o acesso a objetos Python, impedindo que múltiplas threads executem bytecode Python simultaneamente dentro de um mesmo processo. Em tarefas que usam intensivamente a CPU, as threads passam mais tempo disputando o acesso ao GIL e realizando trocas de contexto do que executando trabalho útil. Essa sobrecarga (overhead) massiva destrói qualquer ganho teórico do paralelismo.

Conclusão: Para este tipo de problema, o módulo threading não é a ferramenta adequada. Ele é excelente para tarefas I/O-Bound (ex: esperar por respostas de rede, ler arquivos), mas contraproducente para tarefas CPU-Bound.

3. Abordagem Distribuída (2 Clientes)
Esta abordagem é a mais interessante, pois revela a diferença entre o potencial teórico e os desafios práticos da implementação.

Comportamento: A abordagem mostra uma escalabilidade comprometida e ineficiente. Embora a intenção seja dividir o trabalho para acelerar a solução, a sobrecarga da implementação supera os benefícios.

Evidência:

Teoria: Com 2 clientes, o tempo de execução ideal deveria ser aproximadamente (Tempo_Sequencial / 2) + overhead_rede.

Realidade: Em todos os testes, o tempo da abordagem distribuída foi significativamente pior que o da sequencial. No teste de 9 dígitos, a abordagem sequencial levou 10s, enquanto a distribuída levou 56s. Em vez de um ganho de quase 2x, houve uma penalização de mais de 5x.

Causa Raiz (O porquê): A sobrecarga (overhead) do sistema distribuído é excessivamente alta. Isso pode ser causado por:

Protocolo de Comunicação: A forma como o servidor e os clientes trocam informações pode ser ineficiente, com muitas mensagens pequenas, esperas ou bloqueios.

Lógica do Servidor: O servidor pode ser um gargalo, não conseguindo distribuir as tarefas e receber os resultados com rapidez suficiente para compensar o trabalho que está sendo paralelizado.

Serialização de Dados: A conversão de dados para envio pela rede e sua posterior reconstrução pode adicionar um custo significativo, especialmente se feita de forma ineficiente.

Conclusão: Embora a computação distribuída seja a abordagem correta para escalar massivamente este tipo de problema, a implementação atual possui gargalos de desempenho que a tornam inviável. Ela não está escalando positivamente.

Resumo da Análise e Recomendações
Escalabilidade Linear (Sequencial): Funciona como esperado, mas tem um limite prático.

Escalabilidade Negativa (Paralela com threading): Os resultados provam que esta é a abordagem errada para o problema devido ao GIL do Python. A performance piora com o aumento da carga.

Escalabilidade Comprometida (Distribuída): A abordagem com maior potencial teórico foi neutralizada por uma implementação com alta sobrecarga. Atualmente, ela também não escala de forma positiva.

Próximos Passos Sugeridos:

Corrigir o Paralelismo Local: Substituir o módulo threading pelo módulo multiprocessing. Ele utiliza processos em vez de threads, contornando o GIL e permitindo o uso real de múltiplos núcleos de CPU. Espera-se que esta abordagem supere a sequencial em todos os testes mais longos.

Otimizar o Sistema Distribuído: Perfilar e investigar a comunicação entre o servidor e os clientes. O objetivo é reduzir drasticamente a sobrecarga para que o tempo de execução se aproxime do ideal teórico (Tempo_Sequencial / N_Clientes). Analise se o servidor está bloqueando, se o tamanho das tarefas distribuídas é ideal e se a comunicação pode ser minimizada.